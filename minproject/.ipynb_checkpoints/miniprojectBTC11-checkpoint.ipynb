{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5151334-185a-4ef8-af0b-b254126349e2",
   "metadata": {},
   "source": [
    "# 1.Project Setup # Objective: Predict future Bitcoin prices using historical data and machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e84ca49-cf23-4c7d-9d9d-62815ab8c83e",
   "metadata": {},
   "source": [
    "# 2. Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aee5061-4ca7-4aa0-a625-e1dba055a0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv(\"D:\\\\csss\\\\coinmarketcap_06122017.csv\")\n",
    "df.head()\n",
    "print(df.info())\n",
    "#df = pd.read_csv(\"D:\\\\csss\\\\coinmarketcap_06122017.csv\")  # Make sure you're reading a CSV or creating a DataFrame\n",
    "\n",
    "# Display basic statistics for numerical columns\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bef871-fd95-4b98-bf94-99aa719af15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sum of null\",df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999bae7b-eac9-4f09-b914-0de6a8bdfa4d",
   "metadata": {},
   "source": [
    "#  Remove the attributes with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33db483-f961-47a9-8a71-91112449c789",
   "metadata": {},
   "source": [
    "# .3 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7b46df-00cc-4dd2-90a2-6c53e16fd147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"D:\\\\csss\\\\coinmarketcap_06122017.csv\")\n",
    "\n",
    "# Show the number of null values in each column before filling\n",
    "print(\"Sum of null values before filling:\\n\", df.isna().sum())\n",
    "\n",
    "# Replace missing values in 'max_supply' with the mean\n",
    "print(\"Replacing missing values with mean in 'max_supply'\")\n",
    "print(\"Before Replacing max_supply:\\n\", df['max_supply'].head(7))\n",
    "mean_value = df['max_supply'].mean()\n",
    "print(\"\\nMean of 'max_supply' column:\", mean_value)\n",
    "df['max_supply'] = df['max_supply'].fillna(mean_value)\n",
    "print(\"\\nAfter Replacing with Mean:\\n\", df['max_supply'].head(7))\n",
    "\n",
    "# Replace missing values in 'available_supply' with the median\n",
    "print(\"\\nReplacing missing values with median in 'available_supply'\")\n",
    "print(\"Before Replacing available_supply:\\n\", df['available_supply'].head(7))\n",
    "median_value = df['available_supply'].median()\n",
    "print(\"\\nMedian of 'available_supply' column:\", median_value)\n",
    "df['available_supply'] = df['available_supply'].fillna(median_value)\n",
    "print(\"\\nAfter Replacing with Median:\\n\", df['available_supply'].head(7))\n",
    "\n",
    "# Replace missing values in 'market_cap_usd' with the mode\n",
    "print(\"\\nReplacing missing values with mode in 'market_cap_usd'\")\n",
    "print(\"Before Replacing market_cap_usd:\\n\", df['market_cap_usd'].head(7))\n",
    "mode_value = df['market_cap_usd'].mode()[0]\n",
    "print(\"\\nMode of 'market_cap_usd' column:\", mode_value)\n",
    "df['market_cap_usd'] = df['market_cap_usd'].fillna(mode_value)\n",
    "print(\"\\nAfter Replacing with Mode:\\n\", df['market_cap_usd'].head(7))\n",
    "\n",
    "# Replace missing values in 'total_supply' with the mode\n",
    "print(\"\\nReplacing missing values with mode in 'total_supply'\")\n",
    "print(\"Before Replacing total_supply:\\n\", df['total_supply'].head(7))\n",
    "mode_value_total_supply = df['total_supply'].mode()[0]\n",
    "print(\"\\nMode of 'total_supply' column:\", mode_value_total_supply)\n",
    "df['total_supply'] = df['total_supply'].fillna(mode_value_total_supply)\n",
    "print(\"\\nAfter Replacing with Mode:\\n\", df['total_supply'].head(7))\n",
    "\n",
    "# Replace missing values in 'percent_change_7d' with the mode\n",
    "percent_change_7d_mode = df['percent_change_7d'].mode()[0]\n",
    "print(\"\\nMode of 'percent_change_7d':\", percent_change_7d_mode)\n",
    "df['percent_change_7d'] = df['percent_change_7d'].fillna(percent_change_7d_mode)\n",
    "\n",
    "# Replace missing values in 'percent_change_24h' with the mode\n",
    "percent_change_24h_mode = df['percent_change_24h'].mode()[0]\n",
    "print(\"\\nMode of 'percent_change_24h':\", percent_change_24h_mode)\n",
    "df['percent_change_24h'] = df['percent_change_24h'].fillna(percent_change_24h_mode)\n",
    "\n",
    "# Replace remaining NaN values with -1\n",
    "df = df.replace({np.nan: -1})\n",
    "\n",
    "# Show the number of null values in each column after filling\n",
    "print(\"\\nSum of null values after filling:\\n\", df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71b2a40-e2f1-4c8f-9f75-a0290109da6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8e6c0d-6cab-4345-9220-ca79c8eb9db5",
   "metadata": {},
   "source": [
    "# remove outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335d1e6c-2b02-4c2a-b088-fd05d675fefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming the correct column is 'price_btc'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df['price_btc'])\n",
    "plt.ylabel('Price in BTC')\n",
    "plt.title('Distribution of Price in BTC')\n",
    "plt.show()\n",
    "# Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "Q1 = df['price_btc'].quantile(0.25)\n",
    "Q3 = df['price_btc'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define outlier boundaries\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "print(f'Lower Bound: {lower_bound}, Upper Bound: {upper_bound}')\n",
    "# Filter out rows where 'price_btc' is an outlier\n",
    "df_filtered = df[(df['price_btc'] >= lower_bound) & (df['price_btc'] <= upper_bound)]\n",
    "\n",
    "# Check how many rows were removed\n",
    "print(f'Original data size: {df.shape[0]}')\n",
    "print(f'Filtered data size: {df_filtered.shape[0]}')\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_filtered['price_btc'])\n",
    "plt.ylabel('Price in BTC (without outliers)')\n",
    "plt.title('Distribution of Price in BTC After Removing Outliers')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2dbbd2-650b-4c0c-94aa-b75c4c828ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Boxplot for '24h_volume_usd'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df['24h_volume_usd'])\n",
    "plt.ylabel('24h Volume (USD)')\n",
    "plt.title('Distribution of 24h Volume (USD)')\n",
    "plt.show()\n",
    "\n",
    "# Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "Q1 = df['24h_volume_usd'].quantile(0.25)\n",
    "Q3 = df['24h_volume_usd'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define outlier boundaries\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "print(f'Lower Bound: {lower_bound}, Upper Bound: {upper_bound}')\n",
    "\n",
    "# Filter out rows where '24h_volume_usd' is an outlier\n",
    "df_filtered_24h_volume = df[(df['24h_volume_usd'] >= lower_bound) & (df['24h_volume_usd'] <= upper_bound)]\n",
    "\n",
    "# Check how many rows were removed\n",
    "print(f'Original data size: {df.shape[0]}')\n",
    "print(f'Filtered data size: {df_filtered_24h_volume.shape[0]}')\n",
    "\n",
    "# Boxplot after outlier removal\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_filtered_24h_volume['24h_volume_usd'])\n",
    "plt.ylabel('24h Volume (USD) (without outliers)')\n",
    "plt.title('Distribution of 24h Volume (USD) After Removing Outliers')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a80a36-a2f0-4a48-8d57-a689b556914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot for 'available_supply'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df['available_supply'])\n",
    "plt.ylabel('Available Supply')\n",
    "plt.title('Distribution of Available Supply')\n",
    "plt.show()\n",
    "\n",
    "# Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "Q1 = df['available_supply'].quantile(0.25)\n",
    "Q3 = df['available_supply'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define outlier boundaries\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "print(f'Lower Bound: {lower_bound}, Upper Bound: {upper_bound}')\n",
    "\n",
    "# Filter out rows where 'available_supply' is an outlier\n",
    "df_filtered_available_supply = df[(df['available_supply'] >= lower_bound) & (df['available_supply'] <= upper_bound)]\n",
    "\n",
    "# Check how many rows were removed\n",
    "print(f'Original data size: {df.shape[0]}')\n",
    "print(f'Filtered data size: {df_filtered_available_supply.shape[0]}')\n",
    "\n",
    "# Boxplot after outlier removal\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_filtered_available_supply['available_supply'])\n",
    "plt.ylabel('Available Supply (without outliers)')\n",
    "plt.title('Distribution of Available Supply After Removing Outliers')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd298bdd-fb1d-49f3-a72e-759e7f29fffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'last_updated' to datetime if it's not already in that format\n",
    "df['last_updated'] = pd.to_datetime(df['last_updated'])\n",
    "\n",
    "# Plot distribution of 'last_updated'\n",
    "plt.figure(figsize=(10, 6))\n",
    "df['last_updated'].hist(bins=30)\n",
    "plt.xlabel('Last Updated')\n",
    "plt.title('Distribution of Last Updated Timestamps')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d36b0b-4ce7-47b4-8f19-eb1f8c7c3a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot for 'market_cap_usd'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df['market_cap_usd'])\n",
    "plt.ylabel('Market Cap (USD)')\n",
    "plt.title('Distribution of Market Cap (USD)')\n",
    "plt.show()\n",
    "\n",
    "# Calculate IQR and filter out outliers\n",
    "Q1 = df['market_cap_usd'].quantile(0.25)\n",
    "Q3 = df['market_cap_usd'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df_filtered_market_cap = df[(df['market_cap_usd'] >= lower_bound) & (df['market_cap_usd'] <= upper_bound)]\n",
    "print(f'Original data size: {df.shape[0]}')\n",
    "print(f'Filtered data size: {df_filtered_market_cap.shape[0]}')\n",
    "\n",
    "# Boxplot after filtering\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_filtered_market_cap['market_cap_usd'])\n",
    "plt.ylabel('Market Cap (USD) (without outliers)')\n",
    "plt.title('Distribution of Market Cap After Removing Outliers')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d36a893-8eaf-49d9-9544-fe50211fed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot for 'max_supply'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df['max_supply'])\n",
    "plt.ylabel('Max Supply')\n",
    "plt.title('Distribution of Max Supply')\n",
    "plt.show()\n",
    "\n",
    "# Calculate IQR and filter out outliers\n",
    "Q1 = df['max_supply'].quantile(0.25)\n",
    "Q3 = df['max_supply'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df_filtered_max_supply = df[(df['max_supply'] >= lower_bound) & (df['max_supply'] <= upper_bound)]\n",
    "print(f'Original data size: {df.shape[0]}')\n",
    "print(f'Filtered data size: {df_filtered_max_supply.shape[0]}')\n",
    "\n",
    "# Boxplot after filtering\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_filtered_max_supply['max_supply'])\n",
    "plt.ylabel('Max Supply (without outliers)')\n",
    "plt.title('Distribution of Max Supply After Removing Outliers')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e2fe6a-2ef1-4169-8dc9-62b0867cfe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot for 'percent_change_1h'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df['percent_change_1h'])\n",
    "plt.ylabel('Percent Change (1h)')\n",
    "plt.title('Distribution of Percent Change in 1 Hour')\n",
    "plt.show()\n",
    "\n",
    "# Calculate IQR and filter out outliers\n",
    "Q1 = df['percent_change_1h'].quantile(0.25)\n",
    "Q3 = df['percent_change_1h'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df_filtered_percent_change_1h = df[(df['percent_change_1h'] >= lower_bound) & (df['percent_change_1h'] <= upper_bound)]\n",
    "print(f'Original data size: {df.shape[0]}')\n",
    "print(f'Filtered data size: {df_filtered_percent_change_1h.shape[0]}')\n",
    "\n",
    "# Boxplot after filtering\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_filtered_percent_change_1h['percent_change_1h'])\n",
    "plt.ylabel('Percent Change (1h) (without outliers)')\n",
    "plt.title('Distribution of Percent Change (1h) After Removing Outliers')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6adfa6-3b4a-4c47-aaee-d65e1ef08a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot for 'percent_change_24h'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df['percent_change_24h'])\n",
    "plt.ylabel('Percent Change (24h)')\n",
    "plt.title('Distribution of Percent Change in 24 Hours')\n",
    "plt.show()\n",
    "\n",
    "# Calculate IQR and filter out outliers\n",
    "Q1 = df['percent_change_24h'].quantile(0.25)\n",
    "Q3 = df['percent_change_24h'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df_filtered_percent_change_24h = df[(df['percent_change_24h'] >= lower_bound) & (df['percent_change_24h'] <= upper_bound)]\n",
    "print(f'Original data size: {df.shape[0]}')\n",
    "print(f'Filtered data size: {df_filtered_percent_change_24h.shape[0]}')\n",
    "\n",
    "# Boxplot after filtering\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_filtered_percent_change_24h['percent_change_24h'])\n",
    "plt.ylabel('Percent Change (24h) (without outliers)')\n",
    "plt.title('Distribution of Percent Change (24h) After Removing Outliers')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08aecb4-78b3-4e7d-90ef-6cc09676e2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot for 'percent_change_7d'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df['percent_change_7d'])\n",
    "plt.ylabel('Percent Change (7d)')\n",
    "plt.title('Distribution of Percent Change in 7 Days')\n",
    "plt.show()\n",
    "\n",
    "# Calculate IQR and filter out outliers\n",
    "Q1 = df['percent_change_7d'].quantile(0.25)\n",
    "Q3 = df['percent_change_7d'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df_filtered_percent_change_7d = df[(df['percent_change_7d'] >= lower_bound) & (df['percent_change_7d'] <= upper_bound)]\n",
    "print(f'Original data size: {df.shape[0]}')\n",
    "print(f'Filtered data size: {df_filtered_percent_change_7d.shape[0]}')\n",
    "\n",
    "# Boxplot after filtering\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_filtered_percent_change_7d['percent_change_7d'])\n",
    "plt.ylabel('Percent Change (7d) (without outliers)')\n",
    "plt.title('Distribution of Percent Change (7d) After Removing Outliers')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2110a740-7dc2-43a5-820f-20eb99e69f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot for 'price_usd'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df['price_usd'])\n",
    "plt.ylabel('Price in USD')\n",
    "plt.title('Distribution of Price in USD')\n",
    "plt.show()\n",
    "\n",
    "# Calculate IQR and filter out outliers\n",
    "Q1 = df['price_usd'].quantile(0.25)\n",
    "Q3 = df['price_usd'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df_filtered_price_usd = df[(df['price_usd'] >= lower_bound) & (df['price_usd'] <= upper_bound)]\n",
    "print(f'Original data size: {df.shape[0]}')\n",
    "print(f'Filtered data size: {df_filtered_price_usd.shape[0]}')\n",
    "\n",
    "# Boxplot after filtering\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_filtered_price_usd['price_usd'])\n",
    "plt.ylabel('Price in USD (without outliers)')\n",
    "plt.title('Distribution of Price in USD After Removing Outliers')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0a326c-a26c-44b4-9eaf-85eca8f96658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot for 'rank'\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.countplot(x=df['rank'])\n",
    "plt.xlabel('Rank')\n",
    "plt.title('Distribution of Rank')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898c1a66-aebf-46c0-8d42-34bee051675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "print(df.columns)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming the correct column is 'price_btc'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df['price_btc'])\n",
    "plt.ylabel('Price in BTC')\n",
    "plt.title('Distribution of Price in BTC')\n",
    "plt.show()\n",
    "# Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "Q1 = df['price_btc'].quantile(0.25)\n",
    "Q3 = df['price_btc'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define outlier boundaries\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "print(f'Lower Bound: {lower_bound}, Upper Bound: {upper_bound}')\n",
    "# Filter out rows where 'price_btc' is an outlier\n",
    "df_filtered = df[(df['price_btc'] >= lower_bound) & (df['price_btc'] <= upper_bound)]\n",
    "\n",
    "# Check how many rows were removed\n",
    "print(f'Original data size: {df.shape[0]}')\n",
    "print(f'Filtered data size: {df_filtered.shape[0]}')\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_filtered['price_btc'])\n",
    "plt.ylabel('Price in BTC (without outliers)')\n",
    "plt.title('Distribution of Price in BTC After Removing Outliers')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fb664b-7563-43c3-a5a8-781fa801cfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot for 'total_supply'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df['total_supply'])\n",
    "plt.ylabel('Total Supply')\n",
    "plt.title('Distribution of Total Supply')\n",
    "plt.show()\n",
    "\n",
    "# Calculate IQR and filter out outliers\n",
    "Q1 = df['total_supply'].quantile(0.25)\n",
    "Q3 = df['total_supply'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df_filtered_total_supply = df[(df['total_supply'] >= lower_bound) & (df['total_supply'] <= upper_bound)]\n",
    "print(f'Original data size: {df.shape[0]}')\n",
    "print(f'Filtered data size: {df_filtered_total_supply.shape[0]}')\n",
    "\n",
    "# Boxplot after filtering\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_filtered_total_supply['total_supply'])\n",
    "plt.ylabel('Total Supply (without outliers)')\n",
    "plt.title('Distribution of Total Supply After Removing Outliers')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae487fb5-4015-4993-82ba-b8800ac19be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'poly', 'linear']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid, refit=True, verbose=2)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Use the best estimator\n",
    "best_svr = grid.best_estimator_\n",
    "y_pred = best_svr.predict(X_test_scaled)\n",
    "corr = df_filtered_no_outliers.corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba142678-658b-49e9-bdfe-41b6ad4a3119",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_filtered_no_outliers.corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8985b6a9-d70f-448c-a80c-d04aa373e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],  # Kernel coefficient\n",
    "    'kernel': ['rbf', 'poly', 'linear']  # Different kernels to try\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(SVR(), param_grid, refit=True, verbose=2)\n",
    "\n",
    "# Fit the grid search model to find the best hyperparameters\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Use the best estimator from grid search\n",
    "best_svr = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with the optimized SVR model\n",
    "y_pred = best_svr.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "accuracy = r2 * 100\n",
    "\n",
    "# Display formatted results\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"{'Support Vector Regression Results (Tuned)':^60}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"{'Best Parameters':<35}: {grid_search.best_params_}\")\n",
    "print(f\"{'Mean Squared Error (MSE)':<35}: {mse:.2f}\")\n",
    "print(f\"{'R² Score (R2)':<35}: {r2:.4f}\")\n",
    "print(f\"{'Accuracy (%)':<35}: {accuracy:.2f}%\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = df_filtered_no_outliers[features + [target]].corr()\n",
    "\n",
    "# Plot the correlation heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.show()\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize and train the Linear Regression model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the Linear Regression model\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "accuracy_lr = r2_lr * 100\n",
    "\n",
    "# Display formatted results\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"{'Linear Regression Results':^60}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"{'Mean Squared Error (MSE)':<35}: {mse_lr:.2f}\")\n",
    "print(f\"{'R² Score (R2)':<35}: {r2_lr:.4f}\")\n",
    "print(f\"{'Accuracy (%)':<35}: {accuracy_lr:.2f}%\")\n",
    "print(f\"{'='*60}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fbd0bc-c2ed-4cf5-90d9-0232617c8dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Select relevant columns for features and target\n",
    "features = ['market_cap_usd', '24h_volume_usd', 'available_supply', 'percent_change_1h','percent_change_24h', 'percent_change_7d']\n",
    "target = 'price_usd'\n",
    "\n",
    "# Drop rows with missing values in features or target\n",
    "df_filtered = df.dropna(subset=features + [target])\n",
    "\n",
    "# Extract features and target after cleaning the data (no additional outlier removal)\n",
    "X = df_filtered[features]\n",
    "y = df_filtered[target]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features (SVR requires scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the SVR model\n",
    "svr = SVR(kernel='rbf')\n",
    "svr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svr.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "accuracy = r2 * 100\n",
    "\n",
    "# Display formatted results\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"{'Support Vector Regression Results':^60}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"{'Mean Squared Error (MSE)':<35}: {mse:.2f}\")\n",
    "print(f\"{'R² Score (R2)':<35}: {r2:.4f}\")\n",
    "print(f\"{'Accuracy (%)':<35}: {accuracy:.2f}%\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Create a DataFrame to store actual vs predicted values\n",
    "results_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "\n",
    "# Format the results_df for better presentation\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_rows', None)  # Display all rows\n",
    "\n",
    "print(f\"\\nRESULT OF ALL PREDICTIONS:\\n{'='*60}\")\n",
    "print(results_df.head().to_string(index=False))\n",
    "print(f\"\\n{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd711127-f0e3-4193-ad41-2d78f833ee7b",
   "metadata": {},
   "source": [
    "# 4. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4dc3c1-e8d4-420b-97af-33153b16e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the original price with the 7-day and 30-day moving averages to smooth out noise and identify underlying trends.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert the 'last_updated' Unix timestamp to datetime\n",
    "df['date'] = pd.to_datetime(df['last_updated'], unit='s')\n",
    "# Calculate moving averages\n",
    "df['7_day_moving_avg'] = df['price_usd'].rolling(window=7).mean()\n",
    "df['30_day_moving_avg'] = df['price_usd'].rolling(window=30).mean()\n",
    "# Plottings\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df['date'], df['price_usd'], label='Price USD', color='blue')\n",
    "plt.plot(df['date'], df['7_day_moving_avg'], label='7-Day Moving Average', color='red')\n",
    "plt.plot(df['date'], df['30_day_moving_avg'], label='30-Day Moving Average', color='green')\n",
    "plt.title('Historical Price and Moving Averages')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price USD')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2561a70b-cd1e-4b77-8352-fcb7486af17d",
   "metadata": {},
   "source": [
    "# Linear Reggression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e48090-606c-4aba-94c1-5608f3f32e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "Q1 = df_filtered[target].quantile(0.25)\n",
    "Q3 = df_filtered[target].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the acceptable range for price_usd\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Remove rows where price_usd is outside the acceptable range\n",
    "df_filtered_no_price_outliers = df_filtered[(df_filtered[target] >= lower_bound) & (df_filtered[target] <= upper_bound)]\n",
    "\n",
    "# Check how many rows remain after outlier removal\n",
    "print(f\"Rows before outlier removal: {df_filtered.shape[0]}\")\n",
    "print(f\"Rows after removing price_usd outliers: {df_filtered_no_price_outliers.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b15afe6-7f68-4247-96ff-23b2ee7cb501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heat map\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = df_filtered_no_outliers[features + [target]].corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Heatmap of Features and Price')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3915b041-d074-4dae-96c8-78bf3230891b",
   "metadata": {},
   "source": [
    "# linear reggression to predit the price of crypto currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0487640a-4a62-413b-8d0f-511db1457c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b33e4e-4589-4e40-915b-54230fb43e2f",
   "metadata": {},
   "source": [
    "#  1 . Preprocessing the Data\n",
    "The first step is to prepare the data for training, ensuring the input features are properly scaled for SVR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e393871-56eb-446d-bc5e-1c138ac41c21",
   "metadata": {},
   "source": [
    "# 2. Support Vector Regression (SVR)\n",
    "Support Vector Regression (SVR) is sensitive to feature scaling, so we scaled the data in the previous step. Now, we train the SVR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf21bda-2d18-4bb4-b69b-7cf341273496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"D:\\\\csss\\\\coinmarketcap_06122017.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd11ea9-db15-49e1-9e90-4d1e7884e2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Select relevant columns for features and target\n",
    "features = ['market_cap_usd', '24h_volume_usd', 'available_supply', 'percent_change_1h','percent_change_24h', 'percent_change_7d']\n",
    "target = 'price_usd'\n",
    "# Drop rows with missing values in features or target\n",
    "df_filtered = df.dropna(subset=features + [target])\n",
    "\n",
    "# Remove outliers using Z-score\n",
    "z_scores = np.abs(stats.zscore(df_filtered[features + [target]]))\n",
    "df_filtered_no_outliers = df_filtered[(z_scores < 3).all(axis=1)]\n",
    "\n",
    "# Extract features and target after removing outliers\n",
    "X = df_filtered_no_outliers[features]\n",
    "y = df_filtered_no_outliers[target]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features (SVR requires scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the SVR model\n",
    "svr = SVR(kernel='rbf')\n",
    "svr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svr.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "accuracy = r2 * 100\n",
    "\n",
    "# Display formatted results\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"{'Support Vector Regression Results':^60}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"{'Mean Squared Error (MSE)':<35}: {mse:.2f}\")\n",
    "print(f\"{'R² Score (R2)':<35}: {r2:.4f}\")\n",
    "print(f\"{'Accuracy (%)':<35}: {accuracy:.2f}%\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Create a DataFrame to store actual vs predicted values\n",
    "results_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "\n",
    "# Format the results_df for better presentation\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_rows', None)  # Display all rows\n",
    "\n",
    "print(f\"\\nRESULT OF ALL PREDICTIONS:\\n{'='*60}\")\n",
    "print(results_df.head().to_string(index=False))\n",
    "print(f\"\\n{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a3b800-dfee-4ee7-ad04-8d156808600b",
   "metadata": {},
   "source": [
    "# 4. Random Forest Regressor Trees (ExtraTreesRegressor)\n",
    "you can use ExtraTreesRegressor, which is a type of ensemble learning model that creates multiple random decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f374bb39-ace8-4356-9c7a-8a06f91381a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Select relevant columns for features and target\n",
    "features = ['market_cap_usd', '24h_volume_usd', 'available_supply', 'percent_change_1h','percent_change_24h', 'percent_change_7d']\n",
    "target = 'price_usd'\n",
    "\n",
    "# Drop rows with missing values in features or target\n",
    "df_filtered = df.dropna(subset=features + [target])\n",
    "\n",
    "# Remove outliers using Z-score\n",
    "z_scores = np.abs(stats.zscore(df_filtered[features + [target]]))\n",
    "df_filtered_no_outliers = df_filtered[(z_scores < 3).all(axis=1)]\n",
    "\n",
    "# Extract features and target after removing outliers\n",
    "X = df_filtered_no_outliers[features]\n",
    "y = df_filtered_no_outliers[target]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the RandomForestRegressor model\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_regressor.predict(X_test_scaled)\n",
    "\n",
    "# Compute metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R-squared (R²): {r2}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "# Plotting predicted vs actual prices with a legend\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, edgecolor='k', alpha=0.7, label='Predicted', color='blue')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3, label='Actual')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Actual Prices')\n",
    "plt.ylabel('Predicted Prices')\n",
    "plt.title('Random Forest Regression: Actual vs Predicted Prices')\n",
    "\n",
    "# Display legend\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080cc3e1-c006-42a9-b271-da6a2c4f4a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ee615b-32a2-410b-a4bf-0469e3920c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43627e4-29e3-408c-9862-9bf9629c29f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d36d80-5c86-4f9e-a520-02778c4c8788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
